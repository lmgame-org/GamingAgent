{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64\n",
    "from typing import List, Dict, Union\n",
    "from openai import responses  # top-level helper (no explicit client needed)\n",
    "\n",
    "def openai_response(\n",
    "    prompt: str | List[Dict],                       # string or full message list\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    *,\n",
    "    system_prompt: str | None = None,\n",
    "    base64_image: str | None = None,                # embed one inline image if desired\n",
    "    temperature: float = 1.0,\n",
    "    reasoning_effort: str = \"medium\",               # for o1/o3/o4\n",
    "    token_limit: int = 30_000,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a chat, vision, or o-family request to OpenAI and return the assistant's text.\n",
    "\n",
    "    • `prompt` may be a plain string *or* an already-formed messages list.\n",
    "    • If `base64_image` is supplied (and the model supports vision) it’s attached\n",
    "      to the same user message.\n",
    "    • The helper automatically picks the right token/effort field.\n",
    "\n",
    "    Returns the assistant-message content as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- hard caps for frontier models ------------------------------------------------\n",
    "    if \"gpt-4o\" in model and token_limit > 16_384:\n",
    "        token_limit = min(token_limit, 16_384)\n",
    "    elif \"gpt-4.1\" in model and token_limit > 32_768:\n",
    "        token_limit = min(token_limit, 32_768)\n",
    "\n",
    "    # --- build message list -----------------------------------------------------------\n",
    "    if isinstance(prompt, str):\n",
    "        # convert to a minimal chat conversation\n",
    "        user_content: List[Dict] = [{\"type\": \"text\", \"text\": prompt}]\n",
    "        if base64_image and \"o3-mini\" not in model:   # o3-mini = text-only\n",
    "            user_content.insert(\n",
    "                0,\n",
    "                {\"type\": \"image_url\",\n",
    "                 \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "            )\n",
    "        messages: List[Dict] = [{\"role\": \"user\", \"content\": user_content}]\n",
    "        if system_prompt:\n",
    "            messages.insert(0, {\"role\": \"system\", \"content\": system_prompt})\n",
    "    else:\n",
    "        # user supplied full messages list\n",
    "        messages = prompt\n",
    "\n",
    "    # --- choose max-token field + optional reasoning ----------------------------------\n",
    "    is_o_family = any(tag in model for tag in (\"o1\", \"o3\", \"o4\"))\n",
    "    token_field  = \"max_completion_tokens\" if is_o_family else \"max_tokens\"\n",
    "\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        token_field: token_limit,\n",
    "    }\n",
    "\n",
    "    if is_o_family:\n",
    "        params[\"reasoning\"] = {\"effort\": reasoning_effort}\n",
    "    else:\n",
    "        params[\"temperature\"] = temperature\n",
    "\n",
    "    # --- call the endpoint ------------------------------------------------------------\n",
    "    response = responses.create(api_key=os.getenv(\"OPENAI_API_KEY\"), **params)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game_agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
